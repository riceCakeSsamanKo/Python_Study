{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Check for GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate bounding boxes and labels\n",
    "def generate_boxes_and_labels(label_path):\n",
    "    boxes, labels = [], []\n",
    "    with open(label_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        label, x_min, y_min, w, h = map(float, line.strip().split(' '))\n",
    "        label = int(label)\n",
    "        \n",
    "        x_max = x_min + w\n",
    "        y_max = y_min + h\n",
    "\n",
    "        boxes.append([x_min, y_min, x_max, y_max])\n",
    "        labels.append(label)\n",
    "    \n",
    "    return torch.as_tensor(boxes, dtype=torch.float32), torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "def check_ratio(old_size):\n",
    "    h_ratio = 224 / old_size[0]\n",
    "    w_ratio = 224 / old_size[1]\n",
    "    return h_ratio, w_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class PidrayDataset(Dataset):\n",
    "    def __init__(self, transforms, image_dir, annotation_dir):\n",
    "        self.transforms = transforms\n",
    "        self.image_dir = image_dir\n",
    "        self.annotation_dir = annotation_dir\n",
    "        self.img_names = os.listdir(image_dir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.img_names[idx])\n",
    "        label_path = os.path.join(self.annotation_dir, self.img_names[idx].replace('.png', '.txt'))\n",
    "        \n",
    "        old_size = cv2.imread(img_path).shape[:2]\n",
    "        h_ratio, w_ratio = check_ratio(old_size)\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        boxes, labels = generate_boxes_and_labels(label_path)\n",
    "        boxes = boxes * torch.tensor([w_ratio, h_ratio, w_ratio, h_ratio])\n",
    "        \n",
    "        target = {'boxes': boxes, 'labels': labels}\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "# Data transformations\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224))\n",
    "])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, targets = list(zip(*batch))\n",
    "    images = torch.stack(images)\n",
    "    targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_dataset = PidrayDataset(trans, '../pidray/train/images', '../pidray/train/labels')\n",
    "test_dataset = PidrayDataset(trans, '../pidray/test/images', '../pidray/test/labels')\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=12, shuffle=True, collate_fn=collate_fn)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=12, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the model\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    model = models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes + 1)\n",
    "    return model\n",
    "\n",
    "# Classes and model initialization\n",
    "classes = [\"Baton\", \"Pliers\", \"Hammer\", \"Powerbank\", \"Scissors\", \"Wrench\", \"Gun\", \"Bullet\", \n",
    "           \"Sprayer\", \"Handcuffs\", \"Knife\", \"Lighter\"]\n",
    "num_classes = len(classes)\n",
    "\n",
    "model = get_model_instance_segmentation(num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Training\n",
    "num_epochs = 10\n",
    "print('---------------------- Training Start --------------------------')\n",
    "print(f\"Training started at : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "train_start = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_num, (imgs, annotations) in enumerate(train_data_loader):\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "        \n",
    "        loss_dict = model(imgs, annotations)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += losses.item()\n",
    "        \n",
    "        if batch_num % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_num}], Loss: {losses.item():.4f}')\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "    torch.save(model.state_dict(), f'model_epoch_{epoch+1}.pth')\n",
    "\n",
    "print(f\"Training completed at : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total time taken : {time.time() - train_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final model\n",
    "model.load_state_dict(torch.load(f'model_epoch_{num_epochs}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for making predictions\n",
    "def make_prediction(model, img, threshold):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model([img])\n",
    "        for idx in range(len(preds[0]['scores'])):\n",
    "            if preds[0]['scores'][idx] < threshold:\n",
    "                preds[0]['boxes'] = preds[0]['boxes'][:idx]\n",
    "                preds[0]['labels'] = preds[0]['labels'][:idx]\n",
    "                preds[0]['scores'] = preds[0]['scores'][:idx]\n",
    "                break\n",
    "    return preds[0]\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model(model, data_loader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    coco_results = []\n",
    "    for images, targets in data_loader:\n",
    "        images = list(img.to(device) for img in images)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        for target, output in zip(targets, outputs):\n",
    "            image_id = target[\"image_id\"].item()\n",
    "            boxes = output[\"boxes\"].cpu().numpy()\n",
    "            scores = output[\"scores\"].cpu().numpy()\n",
    "            labels = output[\"labels\"].cpu().numpy()\n",
    "            \n",
    "            for box, score, label in zip(boxes, scores, labels):\n",
    "                if score < threshold:\n",
    "                    continue\n",
    "                xmin, ymin, xmax, ymax = box\n",
    "                width, height = xmax - xmin, ymax - ymin\n",
    "                result = {\n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": label,\n",
    "                    \"bbox\": [xmin, ymin, width, height],\n",
    "                    \"score\": score\n",
    "                }\n",
    "                coco_results.append(result)\n",
    "    \n",
    "    return coco_results\n",
    "\n",
    "# COCO evaluation function\n",
    "def coco_evaluation(coco_true, coco_results):\n",
    "    coco_dt = coco_true.loadRes(coco_results)\n",
    "    coco_eval = COCOeval(coco_true, coco_dt, 'bbox')\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    \n",
    "    return coco_eval.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT 파일 준비 (이 예시는 GT 파일이 COCO 포맷이라고 가정)\n",
    "coco_true = COCO('path_to_your_coco_annotations.json')\n",
    "coco_results = evaluate_model(model, test_data_loader, device)\n",
    "evaluation_stats = coco_evaluation(coco_true, coco_results)\n",
    "\n",
    "print(f\"COCO Evaluation Results: {evaluation_stats}\")\n",
    "\n",
    "# Function to plot image from output\n",
    "def plot_image_from_output(img, annotation):\n",
    "    img = img.cpu().permute(1,2,0).numpy()\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    for idx in range(len(annotation[\"boxes\"])):\n",
    "        xmin, ymin, xmax, ymax = annotation[\"boxes\"][idx]\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot\n",
    "_idx = 1\n",
    "print(\"Target : \", test_data_loader.dataset[_idx][1]['labels'])\n",
    "plot_image_from_output(test_data_loader.dataset[_idx][0], test_data_loader.dataset[_idx][1])\n",
    "print(\"Prediction : \", coco_results[_idx]['category_id'])\n",
    "plot_image_from_output(test_data_loader.dataset[_idx][0], coco_results[_idx])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
