{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchinfo import summary\n",
    "import time\n",
    "import cv2\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Baton\", \"Pliers\", \"Hammer\", \"Powerbank\", \n",
    "        \"Scissors\", \"Wrench\", \"Gun\", \"Bullet\", \n",
    "        \"Sprayer\", \"Handcuffs\", \"Knife\", \"Lighter\"]\n",
    "\n",
    "def draw_bounding_boxes(image_path, label_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    with open(label_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image)\n",
    "\n",
    "    for line in lines:\n",
    "        label, x_min, y_min, w, h = map(float, line.strip().split(' '))\n",
    "        label = int(label)\n",
    "        x_min, y_min, w, h = int(x_min), int(y_min), int(w), int(h)\n",
    "\n",
    "        rect = patches.Rectangle((x_min, y_min), w, h, linewidth=2, edgecolor='red', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        plt.text(x_min, y_min, classes[label], color='green', fontsize=12, backgroundcolor='white')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# 예시로 함수를 호출하는 부분\n",
    "image_path = '../pidray/train/images/xray_00101.png'\n",
    "label_path = '../pidray/train/labels/xray_00101.txt'\n",
    "\n",
    "draw_bounding_boxes(image_path, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_boxes(label_path):\n",
    "    boxes = []\n",
    "    with open(label_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        label, x_min, y_min, w, h = map(float, line.strip().split(' '))\n",
    "        label = int(label)\n",
    "        \n",
    "        x_max = x_min+w\n",
    "        y_max = y_min+h\n",
    "\n",
    "        boxes.append([x_min, y_min, x_max, y_max])\n",
    "    \n",
    "    return boxes\n",
    "\n",
    "\n",
    "def generate_labels(label_path):\n",
    "    labels = []\n",
    "    with open(label_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        label, x_min, y_min, w, h = map(float, line.strip().split(' '))\n",
    "        label = int(label)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def check_ratio(new_size, old_size):\n",
    "    h_ratio=new_size[0] / old_size[0]\n",
    "    w_ratio=new_size[1] / old_size[1]\n",
    "    \n",
    "    return (h_ratio, w_ratio)\n",
    "\n",
    "print(generate_boxes(label_path))\n",
    "print(generate_labels(label_path))\n",
    "print(check_ratio((800,800),old_size=cv2.imread('../pidray/train/images/xray_17232.png').shape[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = (800,800)\n",
    "\n",
    "class PidrayDataset(object):\n",
    "    def __init__(self, transforms, image_dir, annotation_dir):\n",
    "        '''\n",
    "        path: path to train folder or test folder\n",
    "        '''\n",
    "        # transform module과 img path 경로를 정의\n",
    "        self.transforms = transforms\n",
    "        self.image_dir = image_dir\n",
    "        self.annotation_dir = annotation_dir\n",
    "        self.img_names = os.listdir(image_dir)\n",
    "\n",
    "    def __getitem__(self, idx): #special method\n",
    "        # load images ad masks\n",
    "        img_path = os.path.join(self.image_dir, self.img_names[idx])\n",
    "        label_path = os.path.join(self.annotation_dir, self.img_names[idx].replace('.png', '.txt'))\n",
    "        \n",
    "        \n",
    "        old_size=cv2.imread(img_path).shape[:2]\n",
    "        h_ratio, w_ratio = check_ratio(new_size, old_size) # 224로 리사이즈시 bbox도 리사이즈 해줄라고함\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        \n",
    "        labels = generate_labels(label_path)\n",
    "        boxes = generate_boxes(label_path)\n",
    "\n",
    "        boxes = np.array(boxes) * np.array([w_ratio, h_ratio, w_ratio, h_ratio]) # 박스 리사이즈\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32) \n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64) \n",
    "        \n",
    "\n",
    "        target = {}\n",
    "        target['labels'] = labels\n",
    "        target['boxes'] = boxes\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "trans = transforms.Compose([  # transforms.Compose : list 내의 작업을 연달아 할 수 있게 호출하는 클래스\n",
    "        transforms.ToTensor(), # ToTensor : numpy 이미지에서 torch 이미지로 변경\n",
    "        transforms.Resize(new_size)\n",
    "    ])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, targets = list(zip(*batch))\n",
    "    images = torch.stack(images)\n",
    "    targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "from sympy import false, true\n",
    "\n",
    "\n",
    "train_dataset = PidrayDataset(trans, '../pidray/baton/images','../pidray/baton/labels')\n",
    "test_dataset = PidrayDataset(trans, '../pidray/easy/images','../pidray/easy/labels')\n",
    "\n",
    "train_batch_size = 12\n",
    "test_batch_size = 12\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, collate_fn = collate_fn, shuffle=true)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, collate_fn = collate_fn, shuffle=false)\n",
    "\n",
    "\n",
    "# 데이터 차원 확인하는 코드\n",
    "# for images, targets in train_data_loader:\n",
    "#     print(\"images: \", images.shape)\n",
    "#     for target in targets:\n",
    "#         print(\"labels: \", target['labels'].shape)\n",
    "#         print(\"boxes: \", target['boxes'].shape)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_instance_segmentation(num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes+1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Baton\", \"Pliers\", \"Hammer\", \"Powerbank\", \n",
    "        \"Scissors\", \"Wrench\", \"Gun\", \"Bullet\", \n",
    "        \"Sprayer\", \"Handcuffs\", \"Knife\", \"Lighter\"]\n",
    "\n",
    "num_classes = len(classes)\n",
    "\n",
    "model = get_model_instance_segmentation(num_classes)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.0001,\n",
    "                                momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------------train start--------------------------')\n",
    "print(f\"학습 시작 시각 : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "train_start = time.time()\n",
    "\n",
    "for epoch in range(3,num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_num, (imgs, annotations) in enumerate(train_data_loader): # 이미지당 타겟개수 맞춰줘야함\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "        loss_dict = model(imgs, annotations) \n",
    "        losses = sum(loss for loss in loss_dict.values())    # 각 배치마다의 loss  \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step() \n",
    "        epoch_loss += losses  # 한 에포크당 loss\n",
    "        \n",
    "        if(batch_num<5):\n",
    "            print(f'epoch : {epoch+1}, batch_num:{batch_num+1}, Loss : {losses}, time : {time.time() - epoch_start}, current_time : {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}') \n",
    "            \n",
    "        if(batch_num%250 == 0 and batch_num > 5):\n",
    "            print(f'epoch : {epoch+1}, batch_num:{batch_num+1}, Loss : {losses}, time : {time.time() - epoch_start}, current_time : {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    \n",
    "    # 설명: torch.save(model.state_dict(), PATH): 모델의 학습된 매개변수만 저장\n",
    "    if epoch % 1 == 0:\n",
    "        torch.save(model.state_dict(),f'./model/model_{epoch}.pt')\n",
    "    print(f'epoch : {epoch+1}, Loss : {epoch_loss}, time : {time.time() - epoch_start}')\n",
    "    \n",
    "print(f\"학습 완료 시간 : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\") \n",
    "print(f\"총 소요시간 : {time.time()-train_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(),f'/model/model_{x}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'./model/model_{11}.pt'))  # load_state_dict() 함수에 전달하기 전에 반드시 역직렬화를 해야 함\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, img, threshold):\n",
    "    model.eval()\n",
    "    preds = model(img)\n",
    "    for id in range(len(preds)) :\n",
    "        idx_list = []\n",
    "\n",
    "        for idx, score in enumerate(preds[id]['scores']) :\n",
    "            if score > threshold : \n",
    "                idx_list.append(idx)\n",
    "\n",
    "        preds[id]['boxes'] = preds[id]['boxes'][idx_list]\n",
    "        preds[id]['labels'] = preds[id]['labels'][idx_list]\n",
    "        preds[id]['scores'] = preds[id]['scores'][idx_list]\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Baton\", \"Pliers\", \"Hammer\", \"Powerbank\", \n",
    "        \"Scissors\", \"Wrench\", \"Gun\", \"Bullet\", \n",
    "        \"Sprayer\", \"Handcuffs\", \"Knife\", \"Lighter\"]\n",
    "\n",
    "# 수정된 plot_image_from_output 함수\n",
    "def plot_image_from_output(img, annotation):\n",
    "    img = img.cpu().permute(1, 2, 0).numpy()\n",
    "    # plt.figure(figsize=(4, 4))\n",
    "    \n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    for idx in range(len(annotation[\"boxes\"])):\n",
    "        xmin, ymin, xmax, ymax = annotation[\"boxes\"][idx].cpu().numpy()\n",
    "        label = classes[annotation['labels'][idx].item()]\n",
    "        color = 'r' if label == 1 else 'g' if label == 2 else 'orange'\n",
    "\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=1, edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(xmin, ymin, label, color='white', backgroundcolor='red')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): \n",
    "    # 테스트셋 배치사이즈= 2\n",
    "    for imgs, annotations in train_data_loader:\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "\n",
    "        pred = make_prediction(model, imgs, 0.7)\n",
    "        print(pred)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _idx in range(12):\n",
    "    print(\"Target : \", annotations[_idx]['labels'])\n",
    "    plot_image_from_output(imgs[_idx], annotations[_idx])\n",
    "    print(\"Prediction : \", pred[_idx]['labels'], \"score : \",pred[_idx]['scores'] )\n",
    "    plot_image_from_output(imgs[_idx], pred[_idx])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 정확도 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "labels = []\n",
    "preds_adj_all = []\n",
    "annot_all = []\n",
    "\n",
    "for im, annot in tqdm(test_data_loader, position = 0, leave = True):\n",
    "    im = list(img.to(device) for img in im)\n",
    "    #annot = [{k: v.to(device) for k, v in t.items()} for t in annot]\n",
    "\n",
    "    for t in annot:\n",
    "        labels += t['labels']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds_adj = make_prediction(model, im, 0.7)\n",
    "        preds_adj = [{k: v.to(torch.device('cpu')) for k, v in t.items()} for t in preds_adj]\n",
    "        preds_adj_all.append(preds_adj)\n",
    "        annot_all.append(annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_ObjectDetection as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_metrics = []\n",
    "for batch_i in range(len(preds_adj_all)):\n",
    "    sample_metrics += utils.get_batch_statistics(preds_adj_all[batch_i], annot_all[batch_i], iou_threshold=0.7) \n",
    "\n",
    "true_positives, pred_scores, pred_labels = [torch.cat(x, 0) for x in list(zip(*sample_metrics))]  # 배치가 전부 합쳐짐\n",
    "precision, recall, AP, f1, ap_class = utils.ap_per_class(true_positives, pred_scores, pred_labels, torch.tensor(labels))\n",
    "mAP = torch.mean(AP)\n",
    "\n",
    "print(f'mAP : {mAP}')\n",
    "for _idx in range(num_classes):\n",
    "    print(f\"{classes[_idx]} AP: {AP[_idx]}\")\n",
    "\n",
    "print(f'AP : {AP}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구조 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model,(12,3,330,330))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
